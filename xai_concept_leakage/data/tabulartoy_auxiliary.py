"""
Adapted from https://github.com/mateoespinosa/concept-quality
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from xai_concept_leakage.data.utils import logits_from_probs

import torch
import torch.nn as nn
import torch.nn.functional as F


# Original experiment discussed in the paper
def produce_data_gt_experiment(
    samples, cov=0.0, num_concepts=3, input_size=7, save_path=None
):
    x = np.zeros((samples, input_size), dtype=np.float32)
    y = np.zeros((samples,), dtype=np.float32)
    labels = np.zeros((samples, 1))

    # Sample the x, y, and z latent variables
    sampled_variables = np.random.multivariate_normal(
        mean=[0, 0, 0],
        cov=[[1, cov, cov], [cov, 1, cov], [cov, cov, 1]],
        size=(samples,),
    )
    x_vars = sampled_variables[:, 0]
    y_vars = sampled_variables[:, 1]
    z_vars = sampled_variables[:, 2]

    # The features are non-linear functions applied to each variable
    features = [
        np.sin(x_vars) + x_vars,
        np.cos(x_vars) + x_vars,
        np.sin(y_vars) + y_vars,
        np.cos(y_vars) + y_vars,
        np.sin(z_vars) + z_vars,
        np.cos(z_vars) + z_vars,
        x_vars**2 + y_vars**2 + z_vars**2,
    ]
    features = np.stack(features, axis=1)

    # The concepts just check if the variables are positive
    x_pos = (x_vars > 0).astype(np.int32)
    y_pos = (y_vars > 0).astype(np.int32)
    z_pos = (z_vars > 0).astype(np.int32)
    concepts = np.squeeze(
        np.stack([x_pos, y_pos, z_pos][:num_concepts], axis=1)
    ).astype(np.float32)

    if num_concepts == 3:
        # The labels are generated by checking if at least two of the
        # latent concepts are greater than zero
        labels[:, 0] = (x_pos + y_pos + z_pos).squeeze()
        # xy:  - a * x_pos * y_pos
        # xyz: - a * x_pos * y_pos * z_pos
        # sin: - a*np.sin(x_pos)
        labels = (labels > 1).astype(np.int32)  # i.e. >=2
    elif num_concepts == 2:
        labels[:, 0] = (x_pos + y_pos).squeeze()
        labels = (labels > 0).astype(np.int32)  # i.e. c0 or c1

    if save_path is not None:
        np.save([features.squeeze(), labels.squeeze(), concepts], save_path)

    return features.squeeze(), labels.squeeze(), concepts


# (samples, input_size), (samples), (samples, num_concepts)


# See also gt_vs_leak experiment with 5 concepts at
# concept-quality/experiments/niching_impurity_benchmark_tabular_toy.ipynb


def generate_tabulartoy_data(
    cov, n_samples, save_folder, split_ratios=[0.7, 0.2, 0.1], num_concepts=3
):
    x, y, c = produce_data_gt_experiment(
        n_samples, cov=cov, num_concepts=num_concepts, input_size=7
    )
    ratio_1 = int((split_ratios[1] + split_ratios[2]) * 1e10) / 1e10
    ratio_2 = int(split_ratios[2] / (split_ratios[1] + split_ratios[2]) * 1e10) / 1e10
    x_train, x_test_temp, c_train, c_test_temp, y_train, y_test_temp = train_test_split(
        x, c, y, test_size=ratio_1, random_state=42
    )
    x_val, x_test, c_val, c_test, y_val, y_test = train_test_split(
        x_test_temp, c_test_temp, y_test_temp, test_size=ratio_2, random_state=42
    )
    from pathlib import Path

    Path(save_folder).mkdir(parents=True, exist_ok=True)
    pd.DataFrame(x_train).to_csv(save_folder + "x_train" + ".csv", index=False)
    pd.DataFrame(x_val).to_csv(save_folder + "x_val" + ".csv", index=False)
    pd.DataFrame(x_test).to_csv(save_folder + "x_test" + ".csv", index=False)

    pd.DataFrame(c_train).to_csv(save_folder + "c_train" + ".csv", index=False)
    pd.DataFrame(c_val).to_csv(save_folder + "c_val" + ".csv", index=False)
    pd.DataFrame(c_test).to_csv(save_folder + "c_test" + ".csv", index=False)

    pd.DataFrame(y_train).to_csv(save_folder + "y_train" + ".csv", index=False)
    pd.DataFrame(y_val).to_csv(save_folder + "y_val" + ".csv", index=False)
    pd.DataFrame(y_test).to_csv(save_folder + "y_test" + ".csv", index=False)

    return x_train, x_val, x_test, c_train, c_val, c_test, y_train, y_val, y_test


def load_tabulartoy_data(save_folder, numpy=False, considered_concepts=["0", "1", "2"]):
    x_train = pd.read_csv(save_folder + "x_train.csv")
    c_train = pd.read_csv(save_folder + "c_train.csv")[considered_concepts]
    y_train = pd.read_csv(save_folder + "y_train.csv")

    x_val = pd.read_csv(save_folder + "x_val.csv")
    c_val = pd.read_csv(save_folder + "c_val.csv")[considered_concepts]
    y_val = pd.read_csv(save_folder + "y_val.csv")

    x_test = pd.read_csv(save_folder + "x_test.csv")
    c_test = pd.read_csv(save_folder + "c_test.csv")[considered_concepts]
    y_test = pd.read_csv(save_folder + "y_test.csv")
    if numpy:
        return [
            x_train.to_numpy(),
            x_val.to_numpy(),
            x_test.to_numpy(),
            c_train.to_numpy(),
            c_val.to_numpy(),
            c_test.to_numpy(),
            y_train.to_numpy(),
            y_val.to_numpy(),
            y_test.to_numpy(),
        ]
    else:
        return [x_train, x_val, x_test, c_train, c_val, c_test, y_train, y_val, y_test]


def TT_dataloaders(
    data_folder,
    num_workers=1,
    batch_size=512,
    considered_concepts=["0", "1", "2"],
    c_logits=False,
):
    (x_train, x_val, x_test, c_train, c_val, c_test, y_train, y_val, y_test) = (
        load_tabulartoy_data(data_folder, considered_concepts=considered_concepts)
    )

    if c_logits:
        c_train, c_val, c_test = [
            logits_from_probs(c) for c in [c_train, c_val, c_test]
        ]

    x = torch.FloatTensor(x_train.to_numpy())
    c = torch.FloatTensor(c_train.to_numpy())
    y = (
        F.one_hot(torch.Tensor(y_train.to_numpy()).type(torch.LongTensor))
        .squeeze(1)
        .type(torch.float)
    )
    y = y.argmax(dim=-1).cpu().detach()
    train_dl = torch.utils.data.DataLoader(
        list(zip(x, y, c)), batch_size=batch_size, num_workers=num_workers
    )

    x = torch.FloatTensor(x_val.to_numpy())
    c = torch.FloatTensor(c_val.to_numpy())
    y = (
        F.one_hot(torch.Tensor(y_val.to_numpy()).type(torch.LongTensor))
        .squeeze(1)
        .type(torch.float)
    )
    y = y.argmax(dim=-1).cpu().detach()
    val_dl = torch.utils.data.DataLoader(
        list(zip(x, y, c)), batch_size=batch_size, num_workers=num_workers
    )

    x = torch.FloatTensor(x_test.to_numpy())
    c = torch.FloatTensor(c_test.to_numpy())
    y = (
        F.one_hot(torch.Tensor(y_test.to_numpy()).type(torch.LongTensor))
        .squeeze(1)
        .type(torch.float)
    )
    y = y.argmax(dim=-1).cpu().detach()
    test_dl = torch.utils.data.DataLoader(
        list(zip(x, y, c)), batch_size=batch_size, num_workers=num_workers
    )
    return train_dl, val_dl, test_dl
